{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs:\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 files belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "ds = image_dataset_from_directory(\n",
    "'tiny_imagenet/train',\n",
    "image_size=(64,64),\n",
    "batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 files belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "ds_train = image_dataset_from_directory(\n",
    "'tiny_imagenet/train',\n",
    "image_size=(64,64),\n",
    "batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_csv('tiny_imagenet/val/val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
    "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 validated image filenames belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "ds_val = valid_datagen.flow_from_dataframe(val_data, directory='tiny_imagenet/val/images/', x_col='File', y_col='Class', target_size=(64, 64),\n",
    "                                                    color_mode='rgb', class_mode='categorical', batch_size=256, shuffle=True, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = int(len(ds)*.8)\n",
    "# val_size = len(ds) - train_size\n",
    "# ds_train = ds.take(train_size)\n",
    "# ds_val = ds.skip(split).take(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_base = keras.applications.vgg19.VGG19(\n",
    "# weights=\"imagenet\",\n",
    "# input_shape=(64, 64, 3),\n",
    "# include_top=False)\n",
    "\n",
    "# conv_base.trainable = False\n",
    "# for layer in conv_base.layers:\n",
    "#     if layer.name == 'block5_conv1':\n",
    "#         set_trainable = True\n",
    "#     if set_trainable:\n",
    "#         layer.trainable = True\n",
    "#     else:\n",
    "#         layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "[\n",
    "layers.RandomFlip(\"horizontal\"),\n",
    "layers.RandomRotation(0.1),\n",
    "layers.RandomZoom(0.2),\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,64,3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(x)\n",
    "\n",
    "for size in [32,64,128,256,512,1024]:\n",
    "    residual = x\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "    residual = layers.Conv2D(size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "x = layers.Dense(1024, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(512, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(200, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "keras.callbacks.ModelCheckpoint(\n",
    "filepath=\"tiny_imagenet_feature_extraction_without_data_augmentation.keras\",\n",
    "save_best_only=True,\n",
    "monitor=\"val_loss\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1809/3125 [================>.............] - ETA: 43s - loss: 5.2034 - accuracy: 0.0120"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "ds_train,\n",
    "epochs=100,\n",
    "validation_data=ds_val,\n",
    "callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
