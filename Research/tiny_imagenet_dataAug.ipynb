{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_cv\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import tensorflow_datasets as tfds\n",
    "from keras_cv import utils\n",
    "from keras_cv.layers import BaseImageAugmentationLayer\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-04 16:22:57.887310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-04 16:22:57.904838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-04 16:22:57.904951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs:\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 files belonging to 200 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-04 16:23:00.673178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-04 16:23:00.673331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-04 16:23:00.673427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-04 16:23:00.987625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-04 16:23:00.987749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-04 16:23:00.987844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-04 16:23:00.987921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21814 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:0a:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "ds_train = image_dataset_from_directory(\n",
    "'tiny_imagenet/train',\n",
    "image_size=(64,64),\n",
    "batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 files belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "ds_val = image_dataset_from_directory(\n",
    "'tiny_imagenet/val',\n",
    "image_size=(64,64),\n",
    "batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomBlend(keras_cv.layers.BaseImageAugmentationLayer):\n",
    "    \"\"\"RandomBlend randomly applies a Multiply or Screen Blend to the images.\n",
    "\n",
    "    Args:\n",
    "      value_range: value_range: a tuple or a list of two elements. The first value\n",
    "        represents the lower bound for values in passed images, the second represents\n",
    "        the upper bound. Images passed to the layer should have values within\n",
    "        `value_range`.\n",
    "      factor: A tuple of two floats, a single float or a\n",
    "        `keras_cv.FactorSampler`. `factor` controls the extent to which the\n",
    "        image is Blend. `factor=0.0` makes this layer perform a no-op\n",
    "        operation, while a value of 1.0 uses the degenerated result entirely.\n",
    "        Values between 0 and 1 result in linear interpolation between the original\n",
    "        image and the multiply or blended image.\n",
    "        Values should be between `0.0` and `1.0`.  If a tuple is used, a `factor` is\n",
    "        sampled between the two values for every image augmented.  If a single float\n",
    "        is used, a value between `0.0` and the passed float is sampled.  In order to\n",
    "        ensure the value is always the same, please pass a tuple with two identical\n",
    "        floats: `(0.5, 0.5)`.\n",
    "      blend_stack: An interger value that controls the amount of times the image is blended \n",
    "        to itself.  A value of 1 allows for the images to be blended once.  In most \n",
    "        cases a value of '1' to '3' will give the best results.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, value_range, factor, blend_stack, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.value_range = value_range\n",
    "        self.factor = utils.parse_factor(factor)\n",
    "        self.blend_stack = blend_stack\n",
    "        self.auto_vectorize = False\n",
    "\n",
    "    def get_random_transformation(self, **kwargs):\n",
    "        # kwargs holds {\"images\": image, \"labels\": label, etc...}\n",
    "        return self.factor() \n",
    "\n",
    "    def augment_image(self, image, transformation=None, **kwargs):\n",
    "\n",
    "        # If blend_stack is set to '0' just return the image.\n",
    "        if(self.blend_stack == 0):\n",
    "            return image\n",
    "\n",
    "        # Convert the image to values between '0' and '1'\n",
    "        image = utils.transform_value_range(image, self.value_range, (0, 1))\n",
    "\n",
    "        # Get a random value, either '0' or '1', to decide if screen of multiply will be performed. \n",
    "        # '0' for multiple. '1' for screen.\n",
    "        multOrScreen = (np.random.randint(2))\n",
    "        \n",
    "        # If '0' perform multiply.\n",
    "        if(multOrScreen==0):\n",
    "\n",
    "            augImg = image * image\n",
    "            # decrement blend_stack\n",
    "            self.blend_stack = self.blend_stack - 1\n",
    "            # While there are still more layers to blend.\n",
    "            while(self.blend_stack > 0):\n",
    "                augImg = augImg * image\n",
    "                self.blend_stack = self.blend_stack - 1\n",
    "            \n",
    "        #  Else perform screen blend.\n",
    "        else:\n",
    "\n",
    "            augImg = 1 - (1 - image) * (1 - image)\n",
    "            # decrement blend_stack\n",
    "            self.blend_stack = self.blend_stack - 1\n",
    "            # While there are still more layers to blend.\n",
    "            while(self.blend_stack > 0):\n",
    "                augImg = 1 - (1 - augImg) * (1 - image)\n",
    "                self.blend_stack = self.blend_stack - 1\n",
    "\n",
    "        # Take the augmented image and blend it back with the original.  Transform is the \n",
    "        # random value between the two factors supplied by the user.\n",
    "        image = (augImg * transformation) + (image * (1-transformation))\n",
    "\n",
    "        # Make sure there is not any image overflow.\n",
    "        image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "        \n",
    "        # Return the image. \n",
    "        return image\n",
    "\n",
    "    def augment_label(self, label, transformation=None, **kwargs):\n",
    "        return label\n",
    "\n",
    "    def augment_bounding_boxes(self, bounding_boxes, transformation=None, **kwargs):\n",
    "        return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = keras_cv.layers.Augmenter(\n",
    "  layers=[\n",
    "      # keras.layers.Rescaling(scale=1./255),\n",
    "      keras_cv.layers.RandomFlip(),\n",
    "      # keras.layers.RandomTranslation(height_factor=0.2,width_factor=0.2),\n",
    "      RandomBlend(value_range=(0, 1), factor=(0.01, 1.0), blend_stack=(2)),\n",
    "      # keras_cv.layers.RandAugment(value_range=(0, 255)),\n",
    "      # keras_cv.layers.CutMix(),\n",
    "      # keras_cv.layers.MixUp()\n",
    "    ]\n",
    ")\n",
    "\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "def augment_data(images, labels):\n",
    "  inputs = {\"images\": images, \"labels\": labels}\n",
    "  outputs = augmenter(inputs)\n",
    "  return outputs['images'], outputs['labels']\n",
    "\n",
    "\n",
    "def label_one_hot(images, labels):\n",
    "  labels = tf.one_hot(labels, 200)\n",
    "  outputs = {\"images\": images, \"labels\": labels}\n",
    "  return outputs['images'], outputs['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val = ds_val.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.map(label_one_hot, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.map(label_one_hot, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n"
     ]
    }
   ],
   "source": [
    "ds_train = ds_train.map(augment_data, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = keras.Input(shape=(64,64,3))\n",
    "# x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(inputs)\n",
    "\n",
    "# for size in [32,64,128,256,512]:\n",
    "#     residual = x\n",
    "    \n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Activation(\"relu\")(x)\n",
    "#     x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Activation(\"relu\")(x)\n",
    "#     x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "#     x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "#     residual = layers.Conv2D(size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
    "#     x = layers.add([x, residual])\n",
    "\n",
    "\n",
    "# x = layers.Flatten()(x)\n",
    "# x = layers.Dropout(0.3)(x)\n",
    "# x = layers.Dense(512, activation=\"relu\")(x)\n",
    "# x = layers.Dropout(0.3)(x)\n",
    "# x = layers.Dense(256, activation=\"relu\")(x)\n",
    "# x = layers.Dropout(0.3)(x)\n",
    "# x = layers.Dense(128, activation=\"relu\")(x)\n",
    "# x = layers.Dropout(0.3)(x)\n",
    "# outputs = layers.Dense(200, activation=\"softmax\")(x)\n",
    "# model = keras.Model(inputs, outputs)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = tf.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# model.compile(\n",
    "#   loss='categorical_crossentropy',\n",
    "#   optimizer=opt,\n",
    "#   metrics=['accuracy']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(ds_train, batch_size=32,validation_data=ds_val, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history2 = model.fit(ds_train, batch_size=32,validation_data=ds_val, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_learning_rate = 0.001\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate,\n",
    "#     decay_steps=100000,\n",
    "#     decay_rate=0.9,\n",
    "#     staircase=True)\n",
    "\n",
    "# epochs = 100\n",
    "# learning_rate = 0.01\n",
    "# decay_rate = learning_rate / epochs\n",
    "# momentum = 0.9\n",
    "# sgd = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "\n",
    "model = keras_cv.models.DenseNet121(\n",
    "    include_rescaling=False, include_top=True, weights=None, input_shape=(64,64,3), classes=200)\n",
    "    \n",
    "model.compile(\n",
    "   loss=losses.CategoricalCrossentropy(),\n",
    "   optimizer=optimizers.SGD(momentum=0.9),\n",
    "   metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-04 16:23:08.983461: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8303\n",
      "2022-11-04 16:23:10.632624: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 109s 32ms/step - loss: 4.6282 - accuracy: 0.0654 - val_loss: 4.1429 - val_accuracy: 0.1116\n",
      "Epoch 2/100\n",
      "3125/3125 [==============================] - 108s 34ms/step - loss: 3.8315 - accuracy: 0.1599 - val_loss: 3.6844 - val_accuracy: 0.1812\n",
      "Epoch 3/100\n",
      "3125/3125 [==============================] - 106s 34ms/step - loss: 3.4390 - accuracy: 0.2217 - val_loss: 3.5653 - val_accuracy: 0.2078\n",
      "Epoch 4/100\n",
      "3125/3125 [==============================] - 107s 34ms/step - loss: 3.1709 - accuracy: 0.2702 - val_loss: 3.3689 - val_accuracy: 0.2460\n",
      "Epoch 5/100\n",
      "3125/3125 [==============================] - 106s 34ms/step - loss: 2.9663 - accuracy: 0.3073 - val_loss: 2.9782 - val_accuracy: 0.3031\n",
      "Epoch 6/100\n",
      "3125/3125 [==============================] - 109s 35ms/step - loss: 2.8025 - accuracy: 0.3363 - val_loss: 2.9784 - val_accuracy: 0.3094\n",
      "Epoch 7/100\n",
      "3125/3125 [==============================] - 107s 34ms/step - loss: 2.6517 - accuracy: 0.3649 - val_loss: 2.9147 - val_accuracy: 0.3223\n",
      "Epoch 8/100\n",
      "3125/3125 [==============================] - 105s 33ms/step - loss: 2.5270 - accuracy: 0.3901 - val_loss: 2.8784 - val_accuracy: 0.3287\n",
      "Epoch 9/100\n",
      "3125/3125 [==============================] - 102s 33ms/step - loss: 2.4208 - accuracy: 0.4112 - val_loss: 2.8504 - val_accuracy: 0.3381\n",
      "Epoch 10/100\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 2.3130 - accuracy: 0.4318 - val_loss: 2.8455 - val_accuracy: 0.3429\n",
      "Epoch 11/100\n",
      "3125/3125 [==============================] - 106s 34ms/step - loss: 2.2208 - accuracy: 0.4522 - val_loss: 2.8252 - val_accuracy: 0.3401\n",
      "Epoch 12/100\n",
      "3125/3125 [==============================] - 110s 35ms/step - loss: 2.1307 - accuracy: 0.4695 - val_loss: 2.6933 - val_accuracy: 0.3751\n",
      "Epoch 13/100\n",
      "3125/3125 [==============================] - 110s 35ms/step - loss: 2.0399 - accuracy: 0.4904 - val_loss: 2.6735 - val_accuracy: 0.3853\n",
      "Epoch 14/100\n",
      "3125/3125 [==============================] - 110s 35ms/step - loss: 1.9615 - accuracy: 0.5063 - val_loss: 2.7301 - val_accuracy: 0.3759\n",
      "Epoch 15/100\n",
      "3125/3125 [==============================] - 102s 33ms/step - loss: 1.8871 - accuracy: 0.5213 - val_loss: 2.6548 - val_accuracy: 0.3919\n",
      "Epoch 16/100\n",
      "3125/3125 [==============================] - 108s 34ms/step - loss: 1.8129 - accuracy: 0.5357 - val_loss: 2.6207 - val_accuracy: 0.4030\n",
      "Epoch 17/100\n",
      "3125/3125 [==============================] - 108s 35ms/step - loss: 1.7420 - accuracy: 0.5508 - val_loss: 2.6747 - val_accuracy: 0.3953\n",
      "Epoch 18/100\n",
      "3125/3125 [==============================] - 103s 33ms/step - loss: 1.6724 - accuracy: 0.5665 - val_loss: 2.6598 - val_accuracy: 0.4017\n",
      "Epoch 19/100\n",
      "3125/3125 [==============================] - 96s 31ms/step - loss: 1.6127 - accuracy: 0.5799 - val_loss: 2.8099 - val_accuracy: 0.3863\n",
      "Epoch 20/100\n",
      "3125/3125 [==============================] - 96s 31ms/step - loss: 1.5412 - accuracy: 0.5947 - val_loss: 2.7828 - val_accuracy: 0.3944\n",
      "Epoch 21/100\n",
      "3125/3125 [==============================] - 106s 34ms/step - loss: 1.4781 - accuracy: 0.6102 - val_loss: 2.8259 - val_accuracy: 0.4020\n",
      "Epoch 22/100\n",
      "3125/3125 [==============================] - 105s 34ms/step - loss: 1.4282 - accuracy: 0.6195 - val_loss: 2.7928 - val_accuracy: 0.4061\n",
      "Epoch 23/100\n",
      "3125/3125 [==============================] - 102s 33ms/step - loss: 1.3690 - accuracy: 0.6327 - val_loss: 2.8902 - val_accuracy: 0.3921\n",
      "Epoch 24/100\n",
      "3125/3125 [==============================] - 105s 34ms/step - loss: 1.3131 - accuracy: 0.6475 - val_loss: 2.8009 - val_accuracy: 0.4095\n",
      "Epoch 25/100\n",
      "3125/3125 [==============================] - 99s 32ms/step - loss: 1.2574 - accuracy: 0.6576 - val_loss: 2.9543 - val_accuracy: 0.3975\n",
      "Epoch 26/100\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 1.2076 - accuracy: 0.6698 - val_loss: 2.8826 - val_accuracy: 0.4048\n",
      "Epoch 27/100\n",
      "3125/3125 [==============================] - 96s 31ms/step - loss: 1.1524 - accuracy: 0.6823 - val_loss: 2.9852 - val_accuracy: 0.3968\n",
      "Epoch 28/100\n",
      "3125/3125 [==============================] - 99s 32ms/step - loss: 1.1015 - accuracy: 0.6946 - val_loss: 2.9826 - val_accuracy: 0.4051\n",
      "Epoch 29/100\n",
      "3125/3125 [==============================] - 107s 34ms/step - loss: 1.0593 - accuracy: 0.7041 - val_loss: 3.0628 - val_accuracy: 0.3968\n",
      "Epoch 30/100\n",
      "3125/3125 [==============================] - 104s 33ms/step - loss: 1.0145 - accuracy: 0.7146 - val_loss: 2.9888 - val_accuracy: 0.4134\n",
      "Epoch 31/100\n",
      "3125/3125 [==============================] - 107s 34ms/step - loss: 0.9714 - accuracy: 0.7234 - val_loss: 2.9928 - val_accuracy: 0.4163\n",
      "Epoch 32/100\n",
      "3125/3125 [==============================] - 106s 34ms/step - loss: 0.9297 - accuracy: 0.7354 - val_loss: 3.0965 - val_accuracy: 0.4110\n",
      "Epoch 33/100\n",
      "3125/3125 [==============================] - 109s 35ms/step - loss: 0.8898 - accuracy: 0.7451 - val_loss: 3.1718 - val_accuracy: 0.3967\n",
      "Epoch 34/100\n",
      "3125/3125 [==============================] - 108s 35ms/step - loss: 0.8601 - accuracy: 0.7513 - val_loss: 3.0823 - val_accuracy: 0.4099\n",
      "Epoch 35/100\n",
      "3125/3125 [==============================] - 107s 34ms/step - loss: 0.8129 - accuracy: 0.7635 - val_loss: 3.2177 - val_accuracy: 0.4082\n",
      "Epoch 36/100\n",
      "3125/3125 [==============================] - 109s 35ms/step - loss: 0.7861 - accuracy: 0.7706 - val_loss: 3.1497 - val_accuracy: 0.4244\n",
      "Epoch 37/100\n",
      "3125/3125 [==============================] - 108s 34ms/step - loss: 0.7511 - accuracy: 0.7786 - val_loss: 3.2344 - val_accuracy: 0.4182\n",
      "Epoch 38/100\n",
      "3125/3125 [==============================] - 109s 35ms/step - loss: 0.7153 - accuracy: 0.7884 - val_loss: 3.3363 - val_accuracy: 0.4123\n",
      "Epoch 39/100\n",
      "3125/3125 [==============================] - 102s 33ms/step - loss: 0.6832 - accuracy: 0.7975 - val_loss: 3.2781 - val_accuracy: 0.4174\n",
      "Epoch 40/100\n",
      "3125/3125 [==============================] - 105s 33ms/step - loss: 0.6632 - accuracy: 0.8027 - val_loss: 3.2930 - val_accuracy: 0.4266\n",
      "Epoch 41/100\n",
      "3125/3125 [==============================] - 107s 34ms/step - loss: 0.6291 - accuracy: 0.8109 - val_loss: 3.4219 - val_accuracy: 0.4069\n",
      "Epoch 42/100\n",
      "3125/3125 [==============================] - 108s 35ms/step - loss: 0.6058 - accuracy: 0.8181 - val_loss: 3.3677 - val_accuracy: 0.4257\n",
      "Epoch 43/100\n",
      "3125/3125 [==============================] - 111s 35ms/step - loss: 0.5800 - accuracy: 0.8255 - val_loss: 3.3579 - val_accuracy: 0.4286\n",
      "Epoch 44/100\n",
      "3125/3125 [==============================] - 104s 33ms/step - loss: 0.5470 - accuracy: 0.8339 - val_loss: 3.5212 - val_accuracy: 0.4081\n",
      "Epoch 45/100\n",
      "3125/3125 [==============================] - 108s 35ms/step - loss: 0.5314 - accuracy: 0.8374 - val_loss: 3.6046 - val_accuracy: 0.4063\n",
      "Epoch 46/100\n",
      "3125/3125 [==============================] - 108s 34ms/step - loss: 0.5096 - accuracy: 0.8450 - val_loss: 3.5109 - val_accuracy: 0.4248\n",
      "Epoch 47/100\n",
      "3125/3125 [==============================] - 106s 34ms/step - loss: 0.4913 - accuracy: 0.8492 - val_loss: 3.5410 - val_accuracy: 0.4225\n",
      "Epoch 48/100\n",
      "3125/3125 [==============================] - 106s 34ms/step - loss: 0.4758 - accuracy: 0.8543 - val_loss: 3.6332 - val_accuracy: 0.4157\n",
      "Epoch 49/100\n",
      "3125/3125 [==============================] - 108s 34ms/step - loss: 0.4591 - accuracy: 0.8593 - val_loss: 3.6435 - val_accuracy: 0.4187\n",
      "Epoch 50/100\n",
      "3125/3125 [==============================] - 108s 35ms/step - loss: 0.4311 - accuracy: 0.8661 - val_loss: 3.6441 - val_accuracy: 0.4199\n",
      "Epoch 51/100\n",
      "3125/3125 [==============================] - 105s 34ms/step - loss: 0.4220 - accuracy: 0.8694 - val_loss: 3.6591 - val_accuracy: 0.4230\n",
      "Epoch 52/100\n",
      "3125/3125 [==============================] - 108s 35ms/step - loss: 0.4080 - accuracy: 0.8738 - val_loss: 3.6777 - val_accuracy: 0.4136\n",
      "Epoch 53/100\n",
      "3125/3125 [==============================] - 106s 34ms/step - loss: 0.3914 - accuracy: 0.8775 - val_loss: 3.6709 - val_accuracy: 0.4229\n",
      "Epoch 54/100\n",
      "3125/3125 [==============================] - 107s 34ms/step - loss: 0.3807 - accuracy: 0.8824 - val_loss: 3.6448 - val_accuracy: 0.4270\n",
      "Epoch 55/100\n",
      "3125/3125 [==============================] - 108s 35ms/step - loss: 0.3622 - accuracy: 0.8871 - val_loss: 3.6856 - val_accuracy: 0.4256\n",
      "Epoch 56/100\n",
      "3125/3125 [==============================] - 109s 35ms/step - loss: 0.3499 - accuracy: 0.8906 - val_loss: 3.7134 - val_accuracy: 0.4206\n",
      "Epoch 57/100\n",
      "3125/3125 [==============================] - 108s 34ms/step - loss: 0.3402 - accuracy: 0.8929 - val_loss: 3.8226 - val_accuracy: 0.4171\n",
      "Epoch 58/100\n",
      "3125/3125 [==============================] - 105s 34ms/step - loss: 0.3299 - accuracy: 0.8961 - val_loss: 3.9344 - val_accuracy: 0.4101\n",
      "Epoch 59/100\n",
      "3125/3125 [==============================] - 104s 33ms/step - loss: 0.3154 - accuracy: 0.9007 - val_loss: 3.8725 - val_accuracy: 0.4197\n",
      "Epoch 60/100\n",
      "3125/3125 [==============================] - 105s 33ms/step - loss: 0.3043 - accuracy: 0.9042 - val_loss: 3.8045 - val_accuracy: 0.4289\n",
      "Epoch 61/100\n",
      "3125/3125 [==============================] - 109s 35ms/step - loss: 0.2980 - accuracy: 0.9061 - val_loss: 3.8758 - val_accuracy: 0.4273\n",
      "Epoch 62/100\n",
      "3125/3125 [==============================] - 106s 34ms/step - loss: 0.2898 - accuracy: 0.9093 - val_loss: 3.8377 - val_accuracy: 0.4356\n",
      "Epoch 63/100\n",
      "3125/3125 [==============================] - 107s 34ms/step - loss: 0.2722 - accuracy: 0.9129 - val_loss: 3.8585 - val_accuracy: 0.4291\n",
      "Epoch 64/100\n",
      "3125/3125 [==============================] - 108s 34ms/step - loss: 0.2701 - accuracy: 0.9144 - val_loss: 3.8557 - val_accuracy: 0.4420\n",
      "Epoch 65/100\n",
      "3125/3125 [==============================] - 105s 34ms/step - loss: 0.2623 - accuracy: 0.9174 - val_loss: 3.9363 - val_accuracy: 0.4266\n",
      "Epoch 66/100\n",
      "3125/3125 [==============================] - 107s 34ms/step - loss: 0.2528 - accuracy: 0.9200 - val_loss: 3.9046 - val_accuracy: 0.4380\n",
      "Epoch 67/100\n",
      "3125/3125 [==============================] - 110s 35ms/step - loss: 0.2498 - accuracy: 0.9211 - val_loss: 3.9678 - val_accuracy: 0.4332\n",
      "Epoch 68/100\n",
      "3125/3125 [==============================] - 107s 34ms/step - loss: 0.2327 - accuracy: 0.9255 - val_loss: 3.9609 - val_accuracy: 0.4374\n",
      "Epoch 69/100\n",
      "3125/3125 [==============================] - 106s 34ms/step - loss: 0.2312 - accuracy: 0.9270 - val_loss: 3.9889 - val_accuracy: 0.4361\n",
      "Epoch 70/100\n",
      "3125/3125 [==============================] - 108s 35ms/step - loss: 0.2256 - accuracy: 0.9289 - val_loss: 4.0333 - val_accuracy: 0.4258\n",
      "Epoch 71/100\n",
      "3125/3125 [==============================] - 108s 35ms/step - loss: 0.2194 - accuracy: 0.9307 - val_loss: 4.2119 - val_accuracy: 0.4180\n",
      "Epoch 72/100\n",
      "3125/3125 [==============================] - 106s 34ms/step - loss: 0.2104 - accuracy: 0.9329 - val_loss: 3.9829 - val_accuracy: 0.4344\n",
      "Epoch 73/100\n",
      "3125/3125 [==============================] - 107s 34ms/step - loss: 0.2032 - accuracy: 0.9352 - val_loss: 4.0533 - val_accuracy: 0.4371\n",
      "Epoch 74/100\n",
      "3125/3125 [==============================] - 108s 34ms/step - loss: 0.2004 - accuracy: 0.9360 - val_loss: 4.0935 - val_accuracy: 0.4306\n",
      "Epoch 75/100\n",
      "3125/3125 [==============================] - 105s 33ms/step - loss: 0.1964 - accuracy: 0.9377 - val_loss: 4.0595 - val_accuracy: 0.4331\n",
      "Epoch 76/100\n",
      "3125/3125 [==============================] - 106s 34ms/step - loss: 0.1908 - accuracy: 0.9386 - val_loss: 4.1422 - val_accuracy: 0.4313\n",
      "Epoch 77/100\n",
      "3125/3125 [==============================] - 107s 34ms/step - loss: 0.1877 - accuracy: 0.9399 - val_loss: 4.2277 - val_accuracy: 0.4253\n",
      "Epoch 78/100\n",
      "3125/3125 [==============================] - 106s 34ms/step - loss: 0.1857 - accuracy: 0.9409 - val_loss: 4.1929 - val_accuracy: 0.4325\n",
      "Epoch 79/100\n",
      "3125/3125 [==============================] - 106s 34ms/step - loss: 0.1814 - accuracy: 0.9418 - val_loss: 4.1625 - val_accuracy: 0.4361\n",
      "Epoch 80/100\n",
      "3125/3125 [==============================] - 108s 35ms/step - loss: 0.1776 - accuracy: 0.9429 - val_loss: 4.2111 - val_accuracy: 0.4260\n",
      "Epoch 81/100\n",
      "3125/3125 [==============================] - 105s 34ms/step - loss: 0.1743 - accuracy: 0.9441 - val_loss: 4.1921 - val_accuracy: 0.4305\n",
      "Epoch 82/100\n",
      "3125/3125 [==============================] - 102s 33ms/step - loss: 0.1668 - accuracy: 0.9468 - val_loss: 4.1622 - val_accuracy: 0.4391\n",
      "Epoch 83/100\n",
      "3125/3125 [==============================] - 109s 35ms/step - loss: 0.1617 - accuracy: 0.9474 - val_loss: 4.2211 - val_accuracy: 0.4364\n",
      "Epoch 84/100\n",
      "3125/3125 [==============================] - 108s 35ms/step - loss: 0.1538 - accuracy: 0.9502 - val_loss: 4.3056 - val_accuracy: 0.4277\n",
      "Epoch 85/100\n",
      "3125/3125 [==============================] - 107s 34ms/step - loss: 0.1541 - accuracy: 0.9509 - val_loss: 4.2910 - val_accuracy: 0.4308\n",
      "Epoch 86/100\n",
      "3125/3125 [==============================] - 106s 34ms/step - loss: 0.1518 - accuracy: 0.9513 - val_loss: 4.2387 - val_accuracy: 0.4334\n",
      "Epoch 87/100\n",
      "3125/3125 [==============================] - 108s 35ms/step - loss: 0.1484 - accuracy: 0.9528 - val_loss: 4.2895 - val_accuracy: 0.4280\n",
      "Epoch 88/100\n",
      "3125/3125 [==============================] - 109s 35ms/step - loss: 0.1461 - accuracy: 0.9529 - val_loss: 4.2866 - val_accuracy: 0.4404\n",
      "Epoch 89/100\n",
      "3125/3125 [==============================] - 108s 35ms/step - loss: 0.1420 - accuracy: 0.9545 - val_loss: 4.2905 - val_accuracy: 0.4298\n",
      "Epoch 90/100\n",
      "3125/3125 [==============================] - 101s 32ms/step - loss: 0.1409 - accuracy: 0.9550 - val_loss: 4.4670 - val_accuracy: 0.4309\n",
      "Epoch 91/100\n",
      "3125/3125 [==============================] - 101s 32ms/step - loss: 0.1324 - accuracy: 0.9571 - val_loss: 4.3231 - val_accuracy: 0.4324\n",
      "Epoch 92/100\n",
      "3125/3125 [==============================] - 95s 30ms/step - loss: 0.1325 - accuracy: 0.9585 - val_loss: 4.3113 - val_accuracy: 0.4369\n",
      "Epoch 93/100\n",
      "3125/3125 [==============================] - 107s 34ms/step - loss: 0.1347 - accuracy: 0.9569 - val_loss: 4.2680 - val_accuracy: 0.4393\n",
      "Epoch 94/100\n",
      "3125/3125 [==============================] - 108s 34ms/step - loss: 0.1294 - accuracy: 0.9581 - val_loss: 4.3380 - val_accuracy: 0.4309\n",
      "Epoch 95/100\n",
      "3125/3125 [==============================] - 109s 35ms/step - loss: 0.1242 - accuracy: 0.9607 - val_loss: 4.4792 - val_accuracy: 0.4307\n",
      "Epoch 96/100\n",
      "3125/3125 [==============================] - 107s 34ms/step - loss: 0.1223 - accuracy: 0.9615 - val_loss: 4.3369 - val_accuracy: 0.4417\n",
      "Epoch 97/100\n",
      "3125/3125 [==============================] - 107s 34ms/step - loss: 0.1202 - accuracy: 0.9613 - val_loss: 4.3480 - val_accuracy: 0.4396\n",
      "Epoch 98/100\n",
      "3125/3125 [==============================] - 111s 36ms/step - loss: 0.1190 - accuracy: 0.9623 - val_loss: 4.3626 - val_accuracy: 0.4403\n",
      "Epoch 99/100\n",
      "3125/3125 [==============================] - 106s 34ms/step - loss: 0.1221 - accuracy: 0.9603 - val_loss: 4.4650 - val_accuracy: 0.4301\n",
      "Epoch 100/100\n",
      "3125/3125 [==============================] - 104s 33ms/step - loss: 0.1164 - accuracy: 0.9633 - val_loss: 4.5042 - val_accuracy: 0.4353\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=ds_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('tinyimagenet_densenet121_blend_flip_32batch_100epochs.npy',history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('tiny_imagenet_flip_blend_densenet_epoch_100_150')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Accuracy Plot\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('Tiny Imagenet - Densenet121 - No Aug - Val: 38.45%')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# # plt.savefig('tiny_imagenet_no_aug.pdf')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
