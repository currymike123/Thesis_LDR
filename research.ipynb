{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thesis Research Notebook <br>\n",
    "### LDR Data Augmentation for Convolutional Neural Network Construction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs:\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 32, 32, 3)\n",
      "(45000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "assert x_train.shape == (50000, 32, 32, 3)\n",
    "assert x_test.shape == (10000, 32, 32, 3)\n",
    "assert y_train.shape == (50000, 1)\n",
    "assert y_test.shape == (10000, 1)\n",
    "\n",
    "x_val = x_train[:5000]\n",
    "y_val = y_train[:5000]\n",
    "x_train = x_train[5000:]\n",
    "y_train = y_train[5000:]\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[127 110 104]\n",
      "[8]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0,0,0])\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_base = tf.keras.applications.vgg19.VGG19(\n",
    "    include_top=False, weights='imagenet', input_tensor=None,\n",
    "    input_shape=[32,32,3], pooling=None, classes=100,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "\n",
    "set_trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Creation \n",
    "model = tf.keras.Sequential([\n",
    "    # First Convolutional Block\n",
    "    # 32 filter layers, Kernel Size of 3 x 3. Relu activation.  Add zeroes all around so the image doesn't change size, Padding='same'.\n",
    "\n",
    "    layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding='same', input_shape=[32, 32, 3]),\n",
    "\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(pool_size=(2, 2),),\n",
    "\n",
    "    #Second Convolution Block\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(pool_size=(2, 2),),\n",
    "\n",
    "    #Third Convolution Block\n",
    "    layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(pool_size=(2, 2),),\n",
    "\n",
    "    #Fourth Convolution Block\n",
    "    layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(pool_size=(2, 2),),\n",
    "\n",
    "    #Fifth Convolution Block\n",
    "    layers.Conv2D(filters=512, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPool2D(pool_size=(2, 2),),\n",
    "    \n",
    "    #Classifer Head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units=2048, activation=\"relu\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(units=1024, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(units=512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(units=256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(units=100, activation=\"softmax\"),\n",
    "    \n",
    "    \n",
    "\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 5.0092 - accuracy: 0.0332 - val_loss: 3.9823 - val_accuracy: 0.1000\n",
      "Epoch 2/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 4.3293 - accuracy: 0.0699 - val_loss: 3.6507 - val_accuracy: 0.1494\n",
      "Epoch 3/30\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 3.9636 - accuracy: 0.1059 - val_loss: 3.4245 - val_accuracy: 0.1800\n",
      "Epoch 4/30\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 3.6789 - accuracy: 0.1385 - val_loss: 3.2340 - val_accuracy: 0.2064\n",
      "Epoch 5/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 3.4295 - accuracy: 0.1771 - val_loss: 3.0900 - val_accuracy: 0.2402\n",
      "Epoch 6/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 3.1957 - accuracy: 0.2146 - val_loss: 2.8824 - val_accuracy: 0.2700\n",
      "Epoch 7/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 2.9869 - accuracy: 0.2485 - val_loss: 2.7588 - val_accuracy: 0.2978\n",
      "Epoch 8/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 2.7967 - accuracy: 0.2872 - val_loss: 2.6939 - val_accuracy: 0.3156\n",
      "Epoch 9/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 2.6333 - accuracy: 0.3173 - val_loss: 2.5736 - val_accuracy: 0.3414\n",
      "Epoch 10/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 2.4619 - accuracy: 0.3534 - val_loss: 2.5254 - val_accuracy: 0.3448\n",
      "Epoch 11/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 2.2996 - accuracy: 0.3884 - val_loss: 2.5299 - val_accuracy: 0.3514\n",
      "Epoch 12/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 2.1245 - accuracy: 0.4257 - val_loss: 2.5310 - val_accuracy: 0.3568\n",
      "Epoch 13/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.9587 - accuracy: 0.4615 - val_loss: 2.5980 - val_accuracy: 0.3652\n",
      "Epoch 14/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.7985 - accuracy: 0.4962 - val_loss: 2.5660 - val_accuracy: 0.3648\n",
      "Epoch 15/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.6489 - accuracy: 0.5363 - val_loss: 2.6377 - val_accuracy: 0.3640\n",
      "Epoch 16/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.4987 - accuracy: 0.5708 - val_loss: 2.7219 - val_accuracy: 0.3682\n",
      "Epoch 17/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.3594 - accuracy: 0.6027 - val_loss: 2.7790 - val_accuracy: 0.3608\n",
      "Epoch 18/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2177 - accuracy: 0.6398 - val_loss: 2.8643 - val_accuracy: 0.3582\n",
      "Epoch 19/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0979 - accuracy: 0.6753 - val_loss: 2.9680 - val_accuracy: 0.3706\n",
      "Epoch 20/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9845 - accuracy: 0.7014 - val_loss: 3.0216 - val_accuracy: 0.3642\n",
      "Epoch 21/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.8785 - accuracy: 0.7332 - val_loss: 3.2768 - val_accuracy: 0.3476\n",
      "Epoch 22/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.7979 - accuracy: 0.7571 - val_loss: 3.2162 - val_accuracy: 0.3620\n",
      "Epoch 23/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.7257 - accuracy: 0.7779 - val_loss: 3.3460 - val_accuracy: 0.3570\n",
      "Epoch 24/30\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 0.6488 - accuracy: 0.7985 - val_loss: 3.4417 - val_accuracy: 0.3562\n",
      "Epoch 25/30\n",
      " 562/1407 [==========>...................] - ETA: 10s - loss: 0.5577 - accuracy: 0.8272"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21336\\815554971.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m )\n",
      "\u001b[1;32mc:\\Users\\Michael\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Michael\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Michael\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Michael\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Michael\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Michael\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2957\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2959\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Michael\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1854\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Michael\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    505\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\Michael\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='SparseCategoricalCrossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(x_val,y_val),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 3.8467 - accuracy: 0.3636\n",
      "test loss, test acc: [3.8467421531677246, 0.3635999858379364]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21336\\332818590.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Train/Test Accuracy Plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Custom_0_30'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy and loss after 30 Epochs\n",
    "\n",
    "\n",
    "caption = 'Base: 32 -> 512, BatchNorm, MaxPool' '\\n' 'Head: 2048 -> 256, Batch Normalization, Dropout 0.4' '\\n'  \n",
    "\n",
    "# Train/Test Accuracy Plot\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Custom_0_30')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.text(-.5,-.5, caption)\n",
    "plt.show()\n",
    "\n",
    "# Train/Test Loss Plot\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Custom_0_100')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.text(-.5,-3.5, caption)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc46703bb5971c1f2ddeec2f51a1b1cbd46d23afb736864c6b7014f70ebc45b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
